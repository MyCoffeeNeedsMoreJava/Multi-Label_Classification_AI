{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL0_h6YpINts",
        "outputId": "e4671706-770c-461a-a6c2-3ed3d585d478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            " AliScrape.py   scrape2.json   scrape5.json   scrape8.json\t   scrape.json\n",
            " mergeData.py   scrape3.json   scrape6.json  'scrape9 copy.json'   splitToDo.py\n",
            " scrape1.json   scrape4.json   scrape7.json   scrape9.json\n"
          ]
        }
      ],
      "source": [
        "#Connect to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls gdrive/MyDrive/dlvr/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6NdLSL8KbLm",
        "outputId": "703dd05c-f187-499a-a74f-650ddc84ebf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting parsel\n",
            "  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from parsel) (4.9.1)\n",
            "Collecting w3lib>=1.19.0\n",
            "  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: six>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from parsel) (1.15.0)\n",
            "Collecting cssselect>=0.9\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: w3lib, cssselect, parsel\n",
            "Successfully installed cssselect-1.1.0 parsel-1.6.0 w3lib-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install parsel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWT2fXHdH6rt"
      },
      "source": [
        "# Scraper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knLzTnePI4pV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "6poPWenjH3Px",
        "outputId": "05d9078c-cc04-433a-b646-9c81082868a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Product Sleep 3s\n",
            "Product Sleep 2s\n",
            "Product Sleep 5s\n",
            "Product Sleep 5s\n",
            "Product Sleep 4s\n",
            "Product Sleep 3s\n",
            "Product Sleep 2s\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d5c6678a54d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Product Sleep \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrapefile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "from parsel import Selector\n",
        "from bs4 import BeautifulSoup\n",
        "from random import randint\n",
        "from time import sleep\n",
        "import random\n",
        "\n",
        "def getCatPage(url, page):\n",
        "    lis = url.split(\"/\")\n",
        "    querystring = {\"trafficChannel\":\"main\",\"catName\":lis[5].split(\".\")[0],\"CatId\":lis[4],\"ltype\":\"wholesale\",\"SortType\":\"total_tranpro_desc\",\"page\":str(page),\"groupsort\":\"1\",\"isrefine\":\"y\"}\n",
        "\n",
        "    payload = \"\"\n",
        "    headers = {\n",
        "        \"cookie\": \"ali_apache_id=33.3.24.190.164855992375.189351.0; XSRF-TOKEN=cebdb283-e098-462b-b5ca-8e7d56368f8a; intl_locale=en_US; xman_f=T00k0g+45+kVyCBXFo+ZGxD4zF9tzVgSvWgXd6Xs6lO7PToQcZ9cOUzrlujs980cc0aNf8b7EtN8yHSnFx4i+JKTnNxoZtVNEoKtF7UwYYJim3Dknb8ZAw==; aep_usuc_f=site=glo&c_tp=DKK&ups_d=0|0|0|0&ups_u_t=1664731016912&region=DK&b_locale=en_US&ae_u_p_s=1; acs_usuc_t=x_csrf=1b0xyd1bhfel9&acs_rt=c8e9ec21ee7443f5a0b657a018169e3f; xman_t=g/CiU0iYUAq/arD8sEi676y5pnqn5FXpwnODC+lXbwNOKECkJCe1oxojkz6oDABz; ali_apache_track=; ali_apache_tracktmp=; e_id=pt90; _m_h5_tk=cbdd747895668e3e0f3b4ff94aa2acb8_1663589691466; _m_h5_tk_enc=b52d006eda32cbd4eefda76070103880; AKA_A2=A; xman_us_f=x_locale=en_US&x_l=0&x_c_chg=0&x_as_i=%7B%22cookieCacheEffectTime%22%3A1663588459153%2C%22isCookieCache%22%3A%22Y%22%2C%22ms%22%3A%220%22%7D&acs_rt=c8e9ec21ee7443f5a0b657a018169e3f; aep_history=keywords%5E%0Akeywords%09%0A%0Aproduct_selloffer%5E%0Aproduct_selloffer%091005004727409574%091005003490461568%094000094534783%094001082200193%0932946165416%091005004689057643%091005004023414962%091005002227573759; JSESSIONID=6881F5C023F49E99EEDEFF91E90204AF; x5secdata=xbc05a7d12dcc09d7ef5da8a91f12b32d41663588244a976937840a-187012451abazd2daa__bx__www.aliexpress.com%3A443%2Fglosearch%2Fapi%2Fproduct; intl_common_forever=BuKhQe7uvgN43rzuNFjDpz6xTVZs880vAT4+v72L0mKtZqg1KIvGbg==; tfstk=cOk1BpVMiu4FlrdU6Ste7lfV_oyRZ9LQ0OZSfeR7nf2OUon1ioXzPcS8oZyyTk1..; l=eBxlqkMILY9Nz14bBOfZnurza77TKIRfguPzaNbMiOCP9L565UrAW6oT-ALBCnMNnstHR3PgPMOyB5YU0y4oh1ZN5AVBDpB3wdLh.; isg=BK-vdts1EA7aTRVZtlo8_slbPsq5VAN2q5aN38E8BZ4lEM4SySUnx6mCkhguaNvu\",\n",
        "        \"authority\": \"FILL\",\n",
        "        \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n",
        "        \"accept-language\": \"en-US,en;q=0.5\",\n",
        "        \"cache-control\": \"max-age=0\",\n",
        "        \"sec-fetch-dest\": \"document\",\n",
        "        \"sec-fetch-mode\": \"navigate\",\n",
        "        \"sec-fetch-site\": \"same-origin\",\n",
        "        \"sec-fetch-user\": \"?1\",\n",
        "        \"sec-gpc\": \"1\",\n",
        "        \"upgrade-insecure-requests\": \"1\",\n",
        "        \"user-agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring)\n",
        "\n",
        "    return parse_search(response)\n",
        "\n",
        "\n",
        "def extract_search(response):\n",
        "    \"\"\"extract json data from search page\"\"\"\n",
        "    sel = Selector(response.text)\n",
        "    # find script with page data in it\n",
        "    script_with_data = sel.xpath('//script[contains(text(),\"window.runParams\")]')\n",
        "    # select page data from javascript variable in script tag using regex\n",
        "    return json.loads(script_with_data.re(r\"window.runParams\\s*=\\s*({.+?});\")[0])\n",
        "def parse_search(response):\n",
        "    \"\"\"Parse search page response for product preview results\"\"\"\n",
        "    data = extract_search(response)\n",
        "    parsed = []\n",
        "    for result in data[\"mods\"][\"itemList\"][\"content\"]:\n",
        "        parsed.append(\n",
        "            {\n",
        "                \"id\": result[\"productId\"],\n",
        "                \"url\": f\"FILL\",\n",
        "                \"type\": result[\"productType\"],  # can be either natural or ad\n",
        "                \"title\": result[\"title\"][\"displayTitle\"],\n",
        "                \"price\": result[\"prices\"][\"salePrice\"][\"minPrice\"],\n",
        "                \"currency\": result[\"prices\"][\"salePrice\"][\"currencyCode\"],\n",
        "                \"trade\": result.get(\"trade\", {}).get(\"tradeDesc\"),  # trade line is not always present\n",
        "                \"thumbnail\": result[\"image\"][\"imgUrl\"].lstrip(\"/\"),\n",
        "                \"store\": {\n",
        "                    \"url\": result[\"store\"][\"storeUrl\"],\n",
        "                    \"name\": result[\"store\"][\"storeName\"],\n",
        "                    \"id\": result[\"store\"][\"storeId\"],\n",
        "                    \"ali_id\": result[\"store\"][\"FILL\"],\n",
        "                },\n",
        "            }\n",
        "        )\n",
        "    return parsed\n",
        "\n",
        "def getProduct(prodId):\n",
        "    url = \"FILL\"+str(prodId)+\".html\"\n",
        "\n",
        "    payload = \"\"\n",
        "    headers = {\n",
        "        \"cookie\": \"ali_apache_id=33.3.24.190.164855992375.189351.0; XSRF-TOKEN=cebdb283-e098-462b-b5ca-8e7d56368f8a; intl_locale=en_US; xman_f=T00k0g+45+kVyCBXFo+ZGxD4zF9tzVgSvWgXd6Xs6lO7PToQcZ9cOUzrlujs980cc0aNf8b7EtN8yHSnFx4i+JKTnNxoZtVNEoKtF7UwYYJim3Dknb8ZAw==; aep_usuc_f=site=glo&c_tp=DKK&ups_d=0|0|0|0&ups_u_t=1664731016912&region=DK&b_locale=en_US&ae_u_p_s=1; acs_usuc_t=x_csrf=1b0xyd1bhfel9&acs_rt=c8e9ec21ee7443f5a0b657a018169e3f; xman_t=g/CiU0iYUAq/arD8sEi676y5pnqn5FXpwnODC+lXbwNOKECkJCe1oxojkz6oDABz; ali_apache_track=; ali_apache_tracktmp=; e_id=pt90; _m_h5_tk=cbdd747895668e3e0f3b4ff94aa2acb8_1663589691466; _m_h5_tk_enc=b52d006eda32cbd4eefda76070103880; AKA_A2=A; xman_us_f=x_locale=en_US&x_l=0&x_c_chg=0&x_as_i=%7B%22cookieCacheEffectTime%22%3A1663588459153%2C%22isCookieCache%22%3A%22Y%22%2C%22ms%22%3A%220%22%7D&acs_rt=c8e9ec21ee7443f5a0b657a018169e3f; aep_history=keywords%5E%0Akeywords%09%0A%0Aproduct_selloffer%5E%0Aproduct_selloffer%091005004727409574%091005003490461568%094000094534783%094001082200193%0932946165416%091005004689057643%091005004023414962%091005002227573759; tfstk=cQENBbZQRUKQdZZXCDo4YFLzrgoOZ3lm6wliS_hFe5tvFvuGiNRxKd1gTJv4hVf..; l=eBxlqkMILY9NzvM9BOfwourza77OSIRAguPzaNbMiOCPONfp5tBAB6oTkq89C3MNh6bHR3PgPMOyBeYBY3tSnxv9gJLRMsHmn; isg=BO_vs6TH0E6Vp9UZ9pp8Pombfgr5lEO269bNHwF8i95lUA9SCWTTBu0A0ljuKBsu; JSESSIONID=8AD018BB354E2640785C6ABB3C61560F; intl_common_forever=Olgl8BsJYFf/7O5KYJ0oCb86XijI/KbH84eWvOEK6QEEqUFy8AhMlg==\",\n",
        "        \"authority\": \"FILL\",\n",
        "        \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n",
        "        \"accept-language\": \"en-US,en;q=0.5\",\n",
        "        \"cache-control\": \"max-age=0\",\n",
        "        \"sec-fetch-dest\": \"document\",\n",
        "        \"sec-fetch-mode\": \"navigate\",\n",
        "        \"sec-fetch-site\": \"same-origin\",\n",
        "        \"sec-fetch-user\": \"?1\",\n",
        "        \"sec-gpc\": \"1\",\n",
        "        \"upgrade-insecure-requests\": \"1\",\n",
        "        \"user-agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    response = requests.request(\"GET\", url, data=payload, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    links = soup.find(\"div\", {\"class\" : \"breadcrumb\"}).find_all('a')\n",
        "    return [link.text for link in links]\n",
        "\n",
        "#cat = getCate()\n",
        "#cat = cat[:5]\n",
        "\n",
        "### Set this value to the file you are scraping\n",
        "scrapefile = \"FILL\"\n",
        "\n",
        "datafile = open(scrapefile,'r')\n",
        "res = json.load(datafile)\n",
        "datafile.close()\n",
        "\n",
        "for link in res[\"todo\"]:\n",
        "    print(link)\n",
        "    for page in range(1, 10):\n",
        "        try:\n",
        "            products = getCatPage(link, page)\n",
        "        except:\n",
        "            print(\"Problem with loading catagory!!!!\")\n",
        "            break\n",
        "        if len(products) < 60: break\n",
        "\n",
        "        for prod in products:\n",
        "            if prod['url'] in res['data'].keys(): continue\n",
        "            try: labels = getProduct(prod['id'])\n",
        "            except:\n",
        "                print(\"Problem with loading product!!!!\")\n",
        "                continue\n",
        "            if len(labels) != 1: res[\"data\"][prod['url']] = labels\n",
        "            delay = randint(1,5)\n",
        "            print(\"Product Sleep \" + str(delay) + \"s\")\n",
        "            sleep(delay)\n",
        "        try:\n",
        "            with open(scrapefile, 'w') as f:\n",
        "                json.dump(res, f, indent = 6)\n",
        "        except:\n",
        "            with open(scrapefile, 'w') as f:\n",
        "                json.dump(res, f, indent = 6)\n",
        "            quit()\n",
        "\n",
        "    res[\"todo\"].remove(link)\n",
        "    try:\n",
        "        with open(scrapefile, 'w') as f:\n",
        "            json.dump(res, f, indent = 6)\n",
        "    except:\n",
        "        with open(scrapefile, 'w') as f:\n",
        "            json.dump(res, f, indent = 6)\n",
        "        quit()\n",
        "    delay = randint(1,5)\n",
        "    print(\"Page Sleep \" + str(delay) + \"s\")\n",
        "    sleep(delay)\n",
        "\n",
        "print(\"Scrape done move to next file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIpKXummH9W2"
      },
      "source": [
        "# Merger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbyUKNnUIHsB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "#do this once you are ready to do the next scrape file\n",
        "scrapefile1 = \"FILL\" #The scrape with empty todo\n",
        "scrapefile2 = \"FILL\" #the scrape with filled todo\n",
        "\n",
        "datafile = open(scrapefile1,'r')\n",
        "scrape1 = json.load(datafile)\n",
        "datafile.close()\n",
        "\n",
        "datafile = open(scrapefile2,'r')\n",
        "scrape2 = json.load(datafile)\n",
        "datafile.close()\n",
        "\n",
        "scrape2[\"data\"] = {**scrape1[\"data\"],  **scrape2[\"data\"]}\n",
        "\n",
        "\n",
        "with open(scrapefile2, 'w') as f:\n",
        "            json.dump(scrape2, f, indent = 6)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
